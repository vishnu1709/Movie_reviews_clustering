{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "documentsp=[]\n",
    "documentsn=[]\n",
    "y=[]\n",
    "c=cx=0\n",
    "for category in movie_reviews.categories():\n",
    "    for fileid in movie_reviews.fileids(category):\n",
    "        if category=='pos':\n",
    "            documentsp.append(movie_reviews.words(fileid))\n",
    "            y.append(1)\n",
    "            c+=1\n",
    "        elif category=='neg':\n",
    "            documentsn.append(movie_reviews.words(fileid))\n",
    "            y.append(0)\n",
    "            cx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rev=nltk.corpus.movie_reviews.words('pos/cv000_29590.txt')\n",
    "rev_list=[]\n",
    "for rev in range(1,11):\n",
    "    #rev_text_msg=rev=nltk.corpus.movie_reviews.words(rev)\n",
    "    review_one_string=\" \".join(documentsp[rev])\n",
    "    review_one_string=review_one_string.replace(',',',')\n",
    "    review_one_string=review_one_string.replace('.','.')\n",
    "    review_one_string=review_one_string.replace(\"\\' \",\"'\")\n",
    "    review_one_string=review_one_string.replace(\" \\'\",\"'\")\n",
    "    rev_list.append(review_one_string)\n",
    "for rev in range(1,11):\n",
    "    #rev_text_msg=rev=nltk.corpus.movie_reviews.words(rev)\n",
    "    review_one_string=\" \".join(documentsn[rev])\n",
    "    review_one_string=review_one_string.replace(',',',')\n",
    "    review_one_string=review_one_string.replace('.','.')\n",
    "    review_one_string=review_one_string.replace(\"\\' \",\"'\")\n",
    "    review_one_string=review_one_string.replace(\" \\'\",\"'\")\n",
    "    rev_list.append(review_one_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect=CountVectorizer(lowercase=True,stop_words='english',min_df=2)\n",
    "X_count_vect=count_vect.fit_transform(rev_list)\n",
    "X_names=count_vect.get_feature_names()\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf=TfidfTransformer(norm=\"l2\")\n",
    "tfidf.fit(X_count_vect)\n",
    "X=tfidf.transform(X_count_vect)\n",
    "XD=pd.DataFrame(X.toarray(),columns=X_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>1960</th>\n",
       "      <th>60</th>\n",
       "      <th>able</th>\n",
       "      <th>accent</th>\n",
       "      <th>accompany</th>\n",
       "      <th>act</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>...</th>\n",
       "      <th>worse</th>\n",
       "      <th>worth</th>\n",
       "      <th>worthwhile</th>\n",
       "      <th>writer</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.278791</td>\n",
       "      <td>0.032970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037194</td>\n",
       "      <td>0.055758</td>\n",
       "      <td>0.037194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053596</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045542</td>\n",
       "      <td>0.045542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 819 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10      1960        60  able  accent  accompany       act    acting  \\\n",
       "0  0.0  0.000000  0.000000   0.0     0.0   0.000000  0.000000  0.000000   \n",
       "1  0.0  0.000000  0.000000   0.0     0.0   0.000000  0.000000  0.056577   \n",
       "2  0.0  0.000000  0.000000   0.0     0.0   0.000000  0.278791  0.032970   \n",
       "3  0.0  0.000000  0.000000   0.0     0.0   0.000000  0.000000  0.000000   \n",
       "4  0.0  0.045542  0.045542   0.0     0.0   0.045542  0.000000  0.000000   \n",
       "\n",
       "   action     actor    ...        worse  worth  worthwhile    writer  written  \\\n",
       "0     0.0  0.000000    ...     0.000000    0.0         0.0  0.000000      0.0   \n",
       "1     0.0  0.000000    ...     0.000000    0.0         0.0  0.000000      0.0   \n",
       "2     0.0  0.000000    ...     0.000000    0.0         0.0  0.000000      0.0   \n",
       "3     0.0  0.000000    ...     0.000000    0.0         0.0  0.000000      0.0   \n",
       "4     0.0  0.030379    ...     0.045542    0.0         0.0  0.045542      0.0   \n",
       "\n",
       "   wrong      year     years      york     young  \n",
       "0    0.0  0.041873  0.000000  0.000000  0.000000  \n",
       "1    0.0  0.127648  0.000000  0.000000  0.000000  \n",
       "2    0.0  0.000000  0.037194  0.055758  0.037194  \n",
       "3    0.0  0.000000  0.000000  0.053596  0.000000  \n",
       "4    0.0  0.000000  0.030379  0.000000  0.060758  \n",
       "\n",
       "[5 rows x 819 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '1960',\n",
       " '60',\n",
       " 'able',\n",
       " 'accent',\n",
       " 'accompany',\n",
       " 'act',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actor']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=XD.keys()\n",
    "l=[]\n",
    "for i in K:\n",
    "    l.append(i)\n",
    "l[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "km=KMeans(n_clusters=2)\n",
    "s=[]\n",
    "review_one_string=\" \".join(documentsn[5])\n",
    "review_one_string=review_one_string.replace(',',',')\n",
    "review_one_string=review_one_string.replace('.','.')\n",
    "review_one_string=review_one_string.replace(\"\\' \",\"'\")\n",
    "review_one_string=review_one_string.replace(\" \\'\",\"'\")\n",
    "s.append(review_one_string)\n",
    "#s[0]=s[0][:30]\n",
    "sx=[]\n",
    "review_one_string=\" \".join(documentsp[5])\n",
    "review_one_string=review_one_string.replace(',',',')\n",
    "review_one_string=review_one_string.replace('.','.')\n",
    "review_one_string=review_one_string.replace(\"\\' \",\"'\")\n",
    "review_one_string=review_one_string.replace(\" \\'\",\"'\")\n",
    "sx.append(review_one_string)\n",
    "s#[0]=s[0][:30]\n",
    "s[0]=[s[0]]\n",
    "#sx[0]=sx[0][:30]\n",
    "sx[0]=[sx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted=km.fit_predict(XD[l])\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvect = TfidfVectorizer()\n",
    "test=[\"my name good deloitte .\"]\n",
    "tvect.fit_transform(XD,y_predicted)\n",
    "sx[0]=tvect.transform(sx[0])\n",
    "km.predict(sx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0]=tvect.transform(s[0])\n",
    "km.predict(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
